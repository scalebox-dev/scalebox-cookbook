from dotenv import load_dotenv
import boto3
import json
import logging
import os
from scalebox import Sandbox

load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def generate_csv_data_with_bedrock(prompt: str, model_id: str = "deepseek.v3-v1:0") -> str:
    """
    ä½¿ç”¨ AWS Bedrock è°ƒç”¨ DeepSeek æ¨¡å‹ç”Ÿæˆ CSV æ•°æ®
    
    Args:
        prompt: ç”Ÿæˆæ•°æ®çš„æç¤ºè¯ï¼Œåº”æ˜ç¡®æŒ‡å®šè¾“å‡º CSV æ ¼å¼
        model_id: Bedrock æ¨¡å‹ ID
        
    Returns:
        ç”Ÿæˆçš„ CSV æ ¼å¼æ•°æ®
    """
    try:
        # è·å– AWS é…ç½®
        region = os.getenv('AWS_REGION', 'eu-north-1')  # é»˜è®¤ä½¿ç”¨ eu-north-1
        bearer_token = os.getenv('AWS_BEDROCK_TOKEN')
        
        # åˆ›å»º Bedrock Runtime å®¢æˆ·ç«¯
        # å¦‚æœæœ‰ Bearer Tokenï¼Œå°†å…¶è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ä¾› boto3 ä½¿ç”¨
        if bearer_token:
            os.environ['AWS_SESSION_TOKEN'] = bearer_token
            logger.info("ä½¿ç”¨ Bearer Token è®¤è¯")
        
        client = boto3.client(
            'bedrock-runtime',
            region_name=region
        )
        
        logger.info(f"è¿æ¥åˆ° AWS Region: {region}")
        
        # æ„å»ºä¸¥æ ¼çš„ CSV è¾“å‡ºè¦æ±‚çš„ prompt
        csv_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®ç”ŸæˆåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ç”Ÿæˆæ•°æ®ï¼š

1. è¾“å‡ºæ ¼å¼ï¼šå¿…é¡»æ˜¯çº¯CSVæ ¼å¼ï¼ˆé€—å·åˆ†éš”å€¼ï¼‰
2. ç¬¬ä¸€è¡Œï¼šå¿…é¡»æ˜¯åˆ—åï¼ˆè¡¨å¤´ï¼‰
3. æ•°æ®è¦æ±‚ï¼šçœŸå®ã€åˆç†ã€å¤šæ ·åŒ–
4. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œåªè¾“å‡ºCSVå†…å®¹
5. ä¸è¦ä½¿ç”¨markdownä»£ç å—æ ‡è®°ï¼ˆå¦‚```csvï¼‰

ä»»åŠ¡ï¼š{prompt}

è¯·ç›´æ¥è¾“å‡ºCSVæ•°æ®ï¼š"""
        
        logger.info(f"è°ƒç”¨ Bedrock æ¨¡å‹: {model_id}")
        
        # è°ƒç”¨ Bedrock APIï¼ˆDeepSeek æ¨¡å‹æ ¼å¼ï¼‰
        request_body = {
            "messages": [
                {
                    "role": "user",
                    "content": csv_prompt
                }
            ],
            "max_tokens": 4096,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        response = client.invoke_model(
            modelId=model_id,
            body=json.dumps(request_body),
            contentType='application/json',
            accept='application/json'
        )
        
        # è§£æå“åº”
        response_body = json.loads(response['body'].read())
        logger.info("æˆåŠŸæ”¶åˆ° Bedrock å“åº”")
        
        # æå–ç”Ÿæˆçš„æ–‡æœ¬
        csv_content = response_body['choices'][0]['message']['content']
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ markdown æ ‡è®°
        csv_content = csv_content.replace('```csv', '').replace('```', '').strip()
        
        return csv_content
        
    except Exception as e:
        logger.error(f"è°ƒç”¨ Bedrock å¤±è´¥: {str(e)}")
        raise


def save_csv_to_sandbox(sandbox: Sandbox, csv_content: str, filename: str = "generated_data.csv") -> str:
    """
    å°† CSV æ•°æ®ä¿å­˜åˆ° Sandbox æ–‡ä»¶ç³»ç»Ÿ
    
    Args:
        sandbox: Sandbox å®ä¾‹
        csv_content: CSV æ ¼å¼çš„å†…å®¹
        filename: ä¿å­˜çš„æ–‡ä»¶å
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    try:
        # åœ¨ Sandbox ä¸­åˆ›å»ºæ–‡ä»¶
        file_path = f"/tmp/{filename}"
        
        # ä½¿ç”¨ Sandbox çš„ files.write æ¥å£å†™å…¥æ•°æ®
        sandbox.files.write(file_path, csv_content)
        
        logger.info(f"CSV æ•°æ®å·²ä¿å­˜åˆ° Sandbox: {file_path}")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
        file_info = sandbox.files.read(file_path)
        logger.info(f"æ–‡ä»¶å¤§å°: {len(file_info)} å­—èŠ‚")
        
        return file_path
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶åˆ° Sandbox å¤±è´¥: {str(e)}")
        raise


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºä½¿ç”¨ AI ç”Ÿæˆ CSV æ•°æ®å¹¶å­˜å‚¨åˆ° Sandbox"""
    
    logger.info("="*60)
    logger.info("CSV æ•°æ®ç”Ÿæˆæ¼”ç¤º")
    logger.info("ä½¿ç”¨ AWS Bedrock DeepSeek + Scalebox Sandbox")
    logger.info("="*60)
    
    # æ­¥éª¤ 1: åˆ›å»º Sandbox å®ä¾‹
    logger.info("\n[æ­¥éª¤ 1/6] åˆ›å»º Sandbox å®ä¾‹...")
    sandbox = Sandbox.create()
    logger.info(f"âœ“ Sandbox åˆ›å»ºæˆåŠŸï¼ŒID: {sandbox.sandbox_id}")
    
    try:
        # æ­¥éª¤ 2: å®šä¹‰æ•°æ®ç”Ÿæˆä»»åŠ¡
        logger.info("\n[æ­¥éª¤ 2/6] å®šä¹‰æ•°æ®ç”Ÿæˆä»»åŠ¡...")
        
        # å¯é€‰çš„æ•°æ®ç”Ÿæˆä»»åŠ¡ç¤ºä¾‹
        data_tasks = [
            {
                "name": "ç”¨æˆ·æ•°æ®",
                "prompt": "ç”Ÿæˆ100æ¡ç”¨æˆ·æ•°æ®ï¼ŒåŒ…å«ï¼šç”¨æˆ·IDã€å§“åã€å¹´é¾„ã€æ€§åˆ«ã€é‚®ç®±ã€æ³¨å†Œæ—¥æœŸ",
                "filename": "users.csv"
            },
            {
                "name": "é”€å”®æ•°æ®",
                "prompt": "ç”Ÿæˆ50æ¡é”€å”®è®°å½•ï¼ŒåŒ…å«ï¼šè®¢å•IDã€äº§å“åç§°ã€æ•°é‡ã€å•ä»·ã€æ€»ä»·ã€é”€å”®æ—¥æœŸã€é”€å”®å‘˜",
                "filename": "sales.csv"
            },
            {
                "name": "äº§å“åº“å­˜",
                "prompt": "ç”Ÿæˆ30æ¡äº§å“åº“å­˜æ•°æ®ï¼ŒåŒ…å«ï¼šäº§å“IDã€äº§å“åç§°ã€åˆ†ç±»ã€åº“å­˜æ•°é‡ã€ä»·æ ¼ã€ä¾›åº”å•†",
                "filename": "inventory.csv"
            }
        ]
        
        # é€‰æ‹©è¦ç”Ÿæˆçš„æ•°æ®ï¼ˆå¯ä»¥ä¿®æ”¹ç´¢å¼•é€‰æ‹©ä¸åŒçš„ä»»åŠ¡ï¼‰
        selected_task = data_tasks[0]
        logger.info(f"âœ“ å·²é€‰æ‹©ä»»åŠ¡: {selected_task['name']}")
        logger.info(f"  æç¤ºè¯: {selected_task['prompt']}")
        
        # æ­¥éª¤ 3: è°ƒç”¨ Bedrock AI ç”Ÿæˆ CSV æ•°æ®
        logger.info("\n[æ­¥éª¤ 3/6] è°ƒç”¨ AWS Bedrock DeepSeek ç”Ÿæˆæ•°æ®...")
        csv_content = generate_csv_data_with_bedrock(selected_task['prompt'])
        logger.info(f"âœ“ æ•°æ®ç”ŸæˆæˆåŠŸï¼Œå…± {len(csv_content)} å­—ç¬¦")
        
        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        preview_lines = csv_content.split('\n')[:6]
        logger.info(f"\næ•°æ®é¢„è§ˆï¼ˆå‰6è¡Œï¼‰:")
        for line in preview_lines:
            logger.info(f"  {line}")
        
        # æ­¥éª¤ 4: ä¿å­˜åˆ° Sandbox
        logger.info(f"\n[æ­¥éª¤ 4/6] ä¿å­˜æ•°æ®åˆ° Sandbox...")
        file_path = save_csv_to_sandbox(sandbox, csv_content, selected_task['filename'])
        logger.info(f"âœ“ æ–‡ä»¶å·²ä¿å­˜: {file_path}")
        
        # æ­¥éª¤ 5: éªŒè¯æ•°æ®
        logger.info(f"\n[æ­¥éª¤ 5/6] éªŒè¯ä¿å­˜çš„æ•°æ®...")
        
        # ç»Ÿè®¡è¡Œæ•°
        result = sandbox.commands.run(f"wc -l {file_path}")
        line_count = result.stdout.strip().split()[0]
        logger.info(f"âœ“ æ•°æ®è¡Œæ•°: {line_count} è¡Œï¼ˆåŒ…å«è¡¨å¤´ï¼‰")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        result = sandbox.commands.run(f"du -h {file_path}")
        file_size = result.stdout.strip().split()[0]
        logger.info(f"âœ“ æ–‡ä»¶å¤§å°: {file_size}")
        
        # æ­¥éª¤ 6: æ˜¾ç¤ºæ‘˜è¦
        logger.info("\n[æ­¥éª¤ 6/6] ç”Ÿæˆå®Œæˆæ‘˜è¦")
        logger.info("="*60)
        logger.info("âœ… CSV æ•°æ®ç”ŸæˆæˆåŠŸï¼")
        logger.info("="*60)
        logger.info(f"æ•°æ®é›†åç§°: {selected_task['name']}")
        logger.info(f"æ–‡ä»¶ä½ç½®: {file_path}")
        logger.info(f"æ•°æ®è¡Œæ•°: {line_count} è¡Œ")
        logger.info(f"æ–‡ä»¶å¤§å°: {file_size}")
        logger.info(f"Sandbox ID: {sandbox.sandbox_id}")
        logger.info("="*60)
        
        # æç¤ºå¦‚ä½•è®¿é—®æ•°æ®
        logger.info("\nğŸ’¡ å¦‚ä½•ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®:")
        logger.info("  1. æ•°æ®å·²ä¿å­˜åœ¨ Sandbox çš„ /tmp ç›®å½•")
        logger.info("  2. å¯ä»¥é€šè¿‡ sandbox.files.read() è¯»å–æ•°æ®")
        logger.info("  3. å¯ä»¥åœ¨ Sandbox ä¸­è¿è¡Œå‘½ä»¤å¤„ç†æ•°æ®")
        logger.info(f"  4. Sandbox ID å¯ç”¨äºåç»­è¿æ¥: {sandbox.sandbox_id}")
        
    except Exception as e:
        logger.error(f"\nâŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    finally:
        # æ¸…ç†èµ„æº
        logger.info("\n[æ¸…ç†] å…³é—­ Sandbox...")
        sandbox.kill()
        logger.info("âœ“ Sandbox å·²å…³é—­")
        logger.info("\næ¼”ç¤ºå®Œæˆï¼\n")


if __name__ == "__main__":
    main()
